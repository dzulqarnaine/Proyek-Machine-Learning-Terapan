# -*- coding: utf-8 -*-
"""Predictive_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p8PHR6D7yvkr8bWU4TCsgQ7OuKDWxc0f

## **1. Import Library**

Mengimport library-library yang dibutuhkan untuk membuat model
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, y_train)

"""## **2. Data Loading**"""

data = pd.read_csv('Medicaldataset.csv')
data.head()

"""## **3. Eksplorasi Data**

### 3.1. Deskripsi Variabel
"""

data.info()

"""**Insight**
- Tidak ada indikasi missing value

Analisis statistik deskriptif pada variabel
"""

data.describe()

"""### 3.2. Menangani Missing Value dan Outlier

Melihat apakah terdapat missing values pada dataset
"""

data.isnull().sum()

"""**Insight**
- Tidak ada missing value

Melihat total kategori pada fitur gender
"""

print(data['Gender'].value_counts())

"""**Insight**
- Terdapat kategori yang hanya ada 18 dari total keseluruhan data dan sangat timpang jumlah data keseluruhan.

Mangganti kategori yang jumlahnya sangat kecil dengan modus dari kategori lain.
"""

Gender = data['Gender'].mode()[0]
data['Gender'] = data['Gender'].replace('Other', Gender)

"""Mengecek dan menangani Outlier"""

numeric = ['Age', 'Gender', 'Heart rate', 'Systolic blood pressure', 'Diastolic blood pressure', 'Blood sugar', 'CK-MB', 'Troponin']
outlierValues = {}
data_before_clipping = data[numeric].copy()

# Deteksi dan Clipping Outlier
for col in numeric:
    q1, q3 = np.percentile(data[col].dropna(), [25, 75])
    iqr = q3 - q1
    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr

    outliers = data[col][(data[col] < lower) | (data[col] > upper)]
    outlierValues[col] = outliers

    data[col] = np.clip(data[col], lower, upper)

# Visualisasi Boxplot SEBELUM Clipping
fig, axes = plt.subplots(1, len(numeric), figsize=(5 * len(numeric), 5))
fig.suptitle("Boxplot Sebelum Clipping", fontsize=18, fontweight='bold')
for ax, col in zip(axes, numeric):
    sns.boxplot(x=data_before_clipping[col], ax=ax, color='salmon')
    ax.set_title(col)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# Visualisasi Boxplot SESUDAH Clipping
fig, axes = plt.subplots(1, len(numeric), figsize=(5 * len(numeric), 5))
fig.suptitle("Boxplot Sesudah Clipping", fontsize=18, fontweight='bold')
for ax, col in zip(axes, numeric):
    sns.boxplot(x=data[col], ax=ax, color='mediumseagreen')
    ax.set_title(col)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""### 3.3. Univariate Analysis

Visualisasi distibusi nilai kolom numerik.
"""

rows, cols = 4, 4
plt.figure(figsize=(5 * cols, 4 * rows))
colors = sns.color_palette("Set2", len(numeric))

for i, col in enumerate(numeric):
    plt.subplot(rows, cols, i + 1)
    if data[col].nunique() > 10:
        sns.histplot(data[col].dropna(), bins=30, kde=True, color=colors[i])
    else:
        sns.countplot(x=data[col], color=colors[i])

    plt.title(f"Distribusi {col}")
    plt.xlabel(col)
    plt.ylabel("Frekuensi")

plt.tight_layout()
plt.show()

"""### 3.4. Multivariate Analysis

Melihat rata rata diabetes dibandingkan fitur lain dalam dataset
"""

sns.countplot(
    x='Result',
    data=data,
    hue='Result',
    palette="pastel",
    edgecolor="black",
    legend=False
)

plt.title("Distribusi Kelas pada Variabel 'result'")
plt.xlabel('Result')
plt.ylabel('Frekuensi')
plt.show()

"""Visualisasikan hubungan antar variabel"""

sns.pairplot(data, diag_kind='kde', kind='scatter', plot_kws={'alpha':0.6, 's':40}, corner=True)
plt.show()

"""Visualisasi correlation matrix"""

numeric = data.select_dtypes(include=['number']).columns

plt.figure(figsize=(10, 8))
correlation_matrix = data[numeric].corr().round(2)

sns.heatmap(
    correlation_matrix,
    annot=True,
    cmap='viridis',
    linewidths=0.5,
    fmt='.2f',
    cbar_kws={"shrink": 0.8}
)

plt.title("Correlation Matrix", fontsize=20)
plt.xticks(rotation=45, fontweight='bold')
plt.yticks(rotation=0, fontweight='bold')
plt.tight_layout()
plt.show()

"""## **4. Data Preparation**

### 4.1. Standarisasi Fitur

Melakukan standarisasi menggunakan StandardScaler untuk menyamakan rentang nilai dan melihat hasil perubahan
"""

numeric = ['Age','Heart rate', 'Systolic blood pressure', 'Diastolic blood pressure', 'Blood sugar', 'CK-MB', 'Troponin']
scaler = StandardScaler()
data[numeric] = scaler.fit_transform(data[numeric])
data.head()

"""### 4.2. Spliting Data

Membagi data menjadi train dan test dengan komposisi 20 % untuk test dan 80% untuk train
"""

X = data.drop(columns=["Result"])
y = data["Result"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

"""## **5. Model Development**

### 5.1. Random Forest

Load model Random Forest
"""

# Parameter grid untuk tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Inisialisasi RandomForestClassifier
random_forest = RandomForestClassifier(random_state=42)

# Inisialisasi GridSearchCV
grid_search_rf = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Fit model dengan tuning hyperparameters
grid_search_rf.fit(X_train, y_train)

# Tampilkan hasil terbaik
print(f"Best Parameters: {grid_search_rf.best_params_}")
print(f"Best Score: {grid_search_rf.best_score_}")

"""### 5.2. Naive Bayes

Load model Naive Bayes
"""

# Parameter grid untuk tuning
param_grid = {
    'alpha': [0.1, 0.5, 1.0, 2.0],
    'fit_prior': [True, False]
}

# Inisialisasi BernoulliNB
naive_bayes = BernoulliNB()

# Inisialisasi GridSearchCV
grid_search_nv = GridSearchCV(estimator=naive_bayes, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Fit model dengan tuning hyperparameters
grid_search_nv.fit(X_train, y_train)

# Tampilkan hasil terbaik
print(f"Best Parameters: {grid_search_nv.best_params_}")
print(f"Best Score: {grid_search_nv.best_score_}")

"""### 5.3 Decision Tree

Load model Decision Tree
"""

# Tentukan parameter grid untuk tuning
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Inisialisasi DecisionTreeClassifier
decision_tree = DecisionTreeClassifier(random_state=42)

# Inisialisasi GridSearchCV
grid_search_dt = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Fit model dengan tuning hyperparameters
grid_search_dt.fit(X_train, y_train)

# Tampilkan hasil terbaik
print(f"Best Parameters: {grid_search_dt.best_params_}")
print(f"Best Score: {grid_search_dt.best_score_}")

"""## **6. Evaluasi Model**

### 6.1. Random Forest

Evaluasi model Random Forest.
"""

# Gunakan parameter terbaik untuk melatih model akhir
rf_model = grid_search_rf.best_estimator_
y_pred_rf = rf_model.predict(X_test)

print(f"Akurasi: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

"""### 6.2. Naive Bayes

Evaluasi model Naive Bayes.
"""

nb_model = grid_search_nv.best_estimator_
y_pred_nb = nb_model.predict(X_test)

print(f"Akurasi: {accuracy_score(y_test, y_pred_nb):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_nb))

# Confusion Matrix
cm_nb = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Reds')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

"""### 6.3. Decision Tree

Evaluasi model Decision Tree.
"""

dt_model = grid_search_dt.best_estimator_
y_pred_dt = dt_model.predict(X_test)

print(f"Akurasi: {accuracy_score(y_test, y_pred_dt):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

# Confusion Matrix
cm_dt = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()