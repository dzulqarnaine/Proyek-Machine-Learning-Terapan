# -*- coding: utf-8 -*-
"""Predictive_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18aGvOgCVqE3WEQIPatObw4j8fODbUBS8

## **1. Import Library**

Mengimport library-library yang dibutuhkan untuk membuat model
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

"""## **2. Data Loading**"""

data = pd.read_csv('Medicaldataset.csv')
data.head()

"""## **3. Eksplorasi Data**

### 3.1. Deskripsi Variabel
"""

data.info()

"""**Insight**:
- Tidak ada missing value ditemukan pada dataset. Hal ini penting untuk memastikan data yang digunakan sudah lengkap dan siap diproses lebih lanjut.

"""

#Analisis statistik deskriptif pada variabel
data.describe()

"""### 3.2. Menangani Missing Value dan Outlier

Melihat apakah terdapat missing values pada dataset
"""

data.isnull().sum()

"""**Insight**
- Tidak ada missing value

Melihat total kategori pada fitur gender
"""

print(data['Gender'].value_counts())

"""**Insight**
- Terdapat kategori yang hanya ada 18 dari total keseluruhan data dan sangat timpang jumlah data keseluruhan.

Mangganti kategori yang jumlahnya sangat kecil dengan modus dari kategori lain.
"""

Gender = data['Gender'].mode()[0]
data['Gender'] = data['Gender'].replace('Other', Gender)

"""Mengecek dan menangani Outlier"""

numeric = ['Age', 'Gender', 'Heart rate', 'Systolic blood pressure', 'Diastolic blood pressure', 'Blood sugar', 'CK-MB', 'Troponin']
outlierValues = {}
data_before_clipping = data[numeric].copy()

# Deteksi dan Clipping Outlier
for col in numeric:
    q1, q3 = np.percentile(data[col].dropna(), [25, 75])
    iqr = q3 - q1
    lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr

    outliers = data[col][(data[col] < lower) | (data[col] > upper)]
    outlierValues[col] = outliers

    data[col] = np.clip(data[col], lower, upper)

# Visualisasi Boxplot SEBELUM Clipping
fig, axes = plt.subplots(1, len(numeric), figsize=(5 * len(numeric), 5))
fig.suptitle("Boxplot Sebelum Clipping", fontsize=18, fontweight='bold')
for ax, col in zip(axes, numeric):
    sns.boxplot(x=data_before_clipping[col], ax=ax, color='salmon')
    ax.set_title(col)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

# Visualisasi Boxplot SESUDAH Clipping
fig, axes = plt.subplots(1, len(numeric), figsize=(5 * len(numeric), 5))
fig.suptitle("Boxplot Sesudah Clipping", fontsize=18, fontweight='bold')
for ax, col in zip(axes, numeric):
    sns.boxplot(x=data[col], ax=ax, color='mediumseagreen')
    ax.set_title(col)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""### 3.3. Univariate Analysis

Visualisasi distibusi nilai kolom numerik.
"""

rows, cols = 4, 4
plt.figure(figsize=(5 * cols, 4 * rows))
colors = sns.color_palette("Set2", len(numeric))

for i, col in enumerate(numeric):
    plt.subplot(rows, cols, i + 1)
    if data[col].nunique() > 10:
        sns.histplot(data[col].dropna(), bins=30, kde=True, color=colors[i])
    else:
        sns.countplot(x=data[col], color=colors[i])

    plt.title(f"Distribusi {col}")
    plt.xlabel(col)
    plt.ylabel("Frekuensi")

plt.tight_layout()
plt.show()

"""### 3.4. Multivariate Analysis

Melihat rata rata diabetes dibandingkan fitur lain dalam dataset
"""

sns.countplot(
    x='Result',
    data=data,
    hue='Result',
    palette="pastel",
    edgecolor="black",
    legend=False
)

plt.title("Distribusi Kelas pada Variabel 'result'")
plt.xlabel('Result')
plt.ylabel('Frekuensi')
plt.show()

"""**Insight**
- Visualisasi ini menunjukkan distribusi dua kelas pada variabel **`Result`**. Dari grafik tersebut, terlihat bahwa jumlah individu yang memiliki label **`positive`** (terkena serangan jantung) lebih banyak dibandingkan dengan yang memiliki label **`negative`** (tidak terkena serangan jantung). Kelas **`positive`** menunjukkan frekuensi yang lebih tinggi, sementara kelas **`negative`** relatif lebih sedikit. Hal ini menunjukkan ketidakseimbangan dalam dataset, yang sering terjadi dalam kasus prediksi penyakit, di mana jumlah pasien yang mengalami kondisi yang ditargetkan (serangan jantung) biasanya lebih sedikit dibandingkan dengan yang tidak mengalami.

Visualisasikan hubungan antar variabel
"""

sns.pairplot(data, diag_kind='kde', kind='scatter', plot_kws={'alpha':0.6, 's':40}, corner=True)
plt.show()

"""**Insight**
- Visualisasi KDE (Kernel Density Estimation) menunjukkan hubungan antara berbagai fitur dalam dataset. **Scatter plot** di bagian bawah diagonal menggambarkan distribusi titik data untuk pasangan variabel yang relevan, memberikan gambaran visual mengenai korelasi antar fitur. Sementara itu, **plot KDE** yang terletak di diagonal menunjukkan distribusi probabilitas dari setiap variabel. Beberapa fitur seperti **Systolic Blood Pressure**, **Diastolic Blood Pressure**, dan **Heart Rate** menunjukkan distribusi yang lebih normal, mencerminkan pola yang lebih konsisten dalam data. Variabel seperti **Blood Sugar** dan **Troponin** menunjukkan distribusi yang lebih terpusat dengan puncak yang jelas, mengindikasikan variasi yang lebih terbatas dalam nilai-nilai tersebut. Sedangkan variabel biner seperti **Gender** menunjukkan distribusi yang terpisah, dengan sedikit pola dalam scatter plot, yang mengindikasikan bahwa faktor ini tidak memiliki korelasi yang kuat dengan variabel lain di dataset.

Visualisasi correlation matrix
"""

numeric = data.select_dtypes(include=['number']).columns

plt.figure(figsize=(10, 8))
correlation_matrix = data[numeric].corr().round(2)

sns.heatmap(
    correlation_matrix,
    annot=True,
    cmap='viridis',
    linewidths=0.5,
    fmt='.2f',
    cbar_kws={"shrink": 0.8}
)

plt.title("Correlation Matrix", fontsize=20)
plt.xticks(rotation=45, fontweight='bold')
plt.yticks(rotation=0, fontweight='bold')
plt.tight_layout()
plt.show()

"""**Insight**
- Matriks korelasi memberikan wawasan tentang hubungan antar fitur numerik dalam dataset. Dari matriks ini, dapat terlihat bahwa **Systolic Blood Pressure** dan **Diastolic Blood Pressure** memiliki korelasi yang cukup tinggi (0.60), yang menunjukkan hubungan yang kuat antara kedua jenis tekanan darah tersebut. **Age** memiliki korelasi positif yang moderat dengan **Troponin** (0.17) dan **Systolic Blood Pressure** (0.02). Sementara itu, **Blood Sugar** memiliki korelasi yang sangat rendah dengan variabel lainnya, yang mengindikasikan bahwa **Blood Sugar** tidak banyak berhubungan dengan faktor-faktor lain dalam dataset ini.
**Heart Rate** dan **Diastolic Blood Pressure** menunjukkan korelasi yang cukup rendah (0.13), namun keduanya tetap berperan dalam menentukan kondisi jantung seseorang. **CK-MB** memiliki korelasi rendah dengan semua variabel.

## **4. Data Preparation**

### 4.1. Standarisasi Fitur

Melakukan standarisasi menggunakan StandardScaler untuk menyamakan rentang nilai dan melihat hasil perubahan
"""

numeric = ['Age','Heart rate', 'Systolic blood pressure', 'Diastolic blood pressure', 'Blood sugar', 'CK-MB', 'Troponin']
scaler = StandardScaler()
data[numeric] = scaler.fit_transform(data[numeric])
data.head()

"""### 4.2. Spliting Data

Membagi data menjadi train dan test dengan komposisi 20 % untuk test dan 80% untuk train
"""

X = data.drop(columns=["Result"])
y = data["Result"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

"""## **5. Model Development**

### 5.1. Random Forest

Load model Random Forest
"""

# Parameter grid untuk tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Inisialisasi RandomForestClassifier
random_forest = RandomForestClassifier(random_state=42)

# Inisialisasi GridSearchCV
grid_search_rf = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Fit model dengan tuning hyperparameters
grid_search_rf.fit(X_train, y_train)

# Tampilkan hasil terbaik
print(f"Best Parameters: {grid_search_rf.best_params_}")
print(f"Best Score: {grid_search_rf.best_score_}")

"""Parameter Terbaik yang didapat : `'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100`

### 5.2. Naive Bayes

Load model Naive Bayes
"""

# Parameter grid untuk tuning
param_grid = {
    'alpha': [0.1, 0.5, 1.0, 2.0],
    'fit_prior': [True, False]
}

# Inisialisasi BernoulliNB
naive_bayes = BernoulliNB()

# Inisialisasi GridSearchCV
grid_search_nv = GridSearchCV(estimator=naive_bayes, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Fit model dengan tuning hyperparameters
grid_search_nv.fit(X_train, y_train)

# Tampilkan hasil terbaik
print(f"Best Parameters: {grid_search_nv.best_params_}")
print(f"Best Score: {grid_search_nv.best_score_}")

"""Parameter Terbaik yang didapat : `'alpha': 1.0, 'fit_prior': True`

### 5.3 Decision Tree

Load model Decision Tree
"""

# Tentukan parameter grid untuk tuning
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt', 'log2']
}

# Inisialisasi DecisionTreeClassifier
decision_tree = DecisionTreeClassifier(random_state=42)

# Inisialisasi GridSearchCV
grid_search_dt = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# Fit model dengan tuning hyperparameters
grid_search_dt.fit(X_train, y_train)

# Tampilkan hasil terbaik
print(f"Best Parameters: {grid_search_dt.best_params_}")
print(f"Best Score: {grid_search_dt.best_score_}")

"""Parameter Terbaik yang didapat : `'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 10`

## **6. Evaluasi Model**

### 6.1. Random Forest
"""

#Parameter terbaik untuk melatih model akhir
best_params_rf = {
    'bootstrap': False,
    'n_estimators': 100,
    'max_depth': None,
    'min_samples_split': 5,
    'min_samples_leaf': 2

}

# Inisialisasi model RandomForestClassifier dengan parameter terbaik
rf_model = RandomForestClassifier(
    n_estimators=best_params_rf['n_estimators'],
    max_depth=best_params_rf['max_depth'],
    min_samples_split=best_params_rf['min_samples_split'],
    min_samples_leaf=best_params_rf['min_samples_leaf'],
    bootstrap=best_params_rf['bootstrap'],
    random_state=42
)

# Latih model dengan data train
rf_model.fit(X_train, y_train)

# Prediksi menggunakan model yang sudah dilatih
y_pred_rf = rf_model.predict(X_test)

"""Evaluasi model Random Forest."""

print(f"Akurasi: {accuracy_score(y_test, y_pred_rf):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

"""### 6.2. Naive Bayes"""

# Parameter terbaik untuk melatih model akhir
best_params_nb = {
    'alpha': 1.0,
    'fit_prior': True
}

# Inisialisasi model Naive Bayes dengan parameter terbaik
nb_model = BernoulliNB(alpha=best_params_nb['alpha'], fit_prior=best_params_nb['fit_prior'])

# Latih model dengan data train
nb_model.fit(X_train, y_train)

# Prediksi menggunakan model yang sudah dilatih
y_pred_nb = nb_model.predict(X_test)

"""Evaluasi model Naive Bayes."""

nb_model = grid_search_nv.best_estimator_
y_pred_nb = nb_model.predict(X_test)

print(f"Akurasi: {accuracy_score(y_test, y_pred_nb):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_nb))

# Confusion Matrix
cm_nb = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Reds')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

"""### 6.3. Decision Tree"""

# Parameter terbaik untuk melatih model akhir
best_params_dt = {
    'criterion': 'gini',
    'max_depth': None,
    'max_features': None,
    'min_samples_leaf': 2,
    'min_samples_split': 10
}

# Inisialisasi model Decision Tree dengan parameter terbaik
dt_model = DecisionTreeClassifier(
    criterion=best_params_dt['criterion'],
    max_depth=best_params_dt['max_depth'],
    max_features=best_params_dt['max_features'],
    min_samples_leaf=best_params_dt['min_samples_leaf'],
    min_samples_split=best_params_dt['min_samples_split'],
    random_state=42
)

# Latih model dengan data train
dt_model.fit(X_train, y_train)

# Prediksi menggunakan model yang sudah dilatih
y_pred_dt = dt_model.predict(X_test)

"""Evaluasi model Decision Tree."""

print(f"Akurasi: {accuracy_score(y_test, y_pred_dt):.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

# Confusion Matrix
cm_dt = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()